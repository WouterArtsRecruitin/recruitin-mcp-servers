{
  "name": "ollama-mcp-server",
  "version": "1.0.0",
  "description": "MCP server for local LLM inference via Ollama - recruitment-focused tools",
  "main": "index.js",
  "type": "module",
  "scripts": {
    "start": "node index.js"
  },
  "dependencies": {
    "@modelcontextprotocol/sdk": "^1.2.0",
    "zod": "^3.22.4"
  },
  "engines": {
    "node": ">=18.0.0"
  }
}
